# Instrukcja uruchomienia projektu Hadoop Streaming na klastrze uczelni

## üìã Wymagania wstƒôpne

- Dostƒôp do maszyny z klastrem Hadoop (BigData25 z zajƒôƒá)
- Zalogowany u≈ºytkownik z uprawnieniami do HDFS i YARN
- Dzia≈ÇajƒÖce us≈Çugi: HDFS, YARN, Hive

## üì¶ Przygotowanie plik√≥w

### 1. Skopiuj folder projektu na maszynƒô uczelni

```bash
# Z lokalnej maszyny (Windows)
scp -r "C:\Users\hubert\Desktop\hadoop-streaming" user@uczelnia:/tmp/projekt_hadoop/

# LUB je≈õli masz Git
git clone <repo_url> /tmp/projekt_hadoop
cd /tmp/projekt_hadoop
```

### 2. Sprawd≈∫ strukturƒô projektu

```bash
cd /tmp/projekt_hadoop
ls -la

# Powinno byƒá:
# input/
#   datasource1/    (100 plik√≥w flights*.csv)
#   datasource4/    (airports.csv)
# src/
#   mapper.py
#   reducer.py
#   combiner.py
#   hive.hql
#   run_mr.sh
#   run_hive.sh
```

## üöÄ Krok 1: Upload danych do HDFS

```bash
# Utw√≥rz strukturƒô katalog√≥w w HDFS
hadoop fs -mkdir -p /user/$(whoami)/projekt1/input
hadoop fs -mkdir -p /user/$(whoami)/projekt1/output_mr3
hadoop fs -mkdir -p /user/$(whoami)/projekt1/output6

# Upload datasource1 (loty - 100 plik√≥w CSV)
hadoop fs -put input/datasource1 /user/$(whoami)/projekt1/input/

# Upload datasource4 (lotniska - airports.csv)
hadoop fs -put input/datasource4 /user/$(whoami)/projekt1/input/

# Weryfikacja
hadoop fs -ls /user/$(whoami)/projekt1/input/datasource1 | wc -l
# Powinno byƒá ~101 (100 plik√≥w + linia nag≈Ç√≥wka)

hadoop fs -ls /user/$(whoami)/projekt1/input/datasource4
# Powinien byƒá airports.csv
```

## üîß Krok 2: Uruchom MapReduce Job

```bash
cd /tmp/projekt_hadoop/src

# Nadaj uprawnienia wykonywania
chmod +x run_mr.sh

# Uruchom MapReduce
bash run_mr.sh \
  /user/$(whoami)/projekt1/input/datasource1 \
  /user/$(whoami)/projekt1/output_mr3

# Skrypt automatycznie:
# - Czy≈õci katalog wyj≈õciowy (je≈õli istnieje)
# - Uruchamia Hadoop Streaming z mapper, combiner, reducer
# - Wy≈õwietla pr√≥bkƒô wynik√≥w
```

### Oczekiwany wynik MapReduce:

```
========================================
MapReduce Job Configuration
========================================
Input directory:  /user/user/projekt1/input/datasource1
Output directory: /user/user/projekt1/output_mr3
========================================
Starting MapReduce job...
...
MapReduce job completed successfully!
========================================
Output location: /user/user/projekt1/output_mr3

Sample output:
----------------------------------------
AYWK,Cancelled,3325,775.23
AYWK,Delayed,3315,762.45
AYWK,On time,3360,780.12
...
```

### Weryfikacja MapReduce:

```bash
# Sprawd≈∫ liczbƒô rekord√≥w wyj≈õciowych (powinno byƒá ~300)
hadoop fs -cat /user/$(whoami)/projekt1/output_mr3/part-* | wc -l

# Sprawd≈∫ format: airport_id,status,flight_count,avg_ticket_price
hadoop fs -cat /user/$(whoami)/projekt1/output_mr3/part-* | head -10
```

## üìä Krok 3: Uruchom Hive Job

```bash
cd /tmp/projekt_hadoop/src

# Nadaj uprawnienia wykonywania
chmod +x run_hive.sh

# Uruchom Hive (JOIN + agregacja + RANK + export do JSON)
bash run_hive.sh \
  /user/$(whoami)/projekt1/input/datasource4 \
  /user/$(whoami)/projekt1/output_mr3 \
  /user/$(whoami)/projekt1/output6
```

### Co robi skrypt Hive:

1. **Tworzy tabele**:
   - `mapreduce_result` - wyniki z MapReduce (datasource3)
   - `airports_raw` - surowa tabela dla lotnisk
   - `airports_table` - VIEW z inteligentnym parsowaniem CSV
   - `output_json` - tabela wyj≈õciowa z JsonSerDe

2. **Wykonuje przetwarzanie**:
   - JOIN `mapreduce_result` z `airports_table` (po airport_id)
   - GROUP BY continent, country
   - Oblicza `total_flights` i `avg_ticket_price` (weighted average)
   - RANK() OVER (PARTITION BY continent ORDER BY total_flights DESC)
   - Export do JSON

3. **Inteligentne parsowanie CSV**:
   - Obs≈Çuguje poprawne rekordy (6 p√≥l)
   - Obs≈Çuguje wadliwe rekordy (7 p√≥l - nazwy z przecinkami)
   - VIEW automatycznie ≈ÇƒÖczy nadmiarowe pola w `airport_name`

### Oczekiwany wynik Hive:

```
========================================
Hive Job Configuration
========================================
Airports data (input):  /user/user/projekt1/input/datasource4
MapReduce result:       /user/user/projekt1/output_mr3
JSON output:            /user/user/projekt1/output6
========================================
Starting Hive job...
...
Hive job completed successfully!
========================================
Output location: /user/user/projekt1/output6

Sample output (first 10 records):
----------------------------------------
{"continent":"Africa","country":"Egypt","total_flights":29850,"avg_ticket_price":765.23,"rank_in_continent":1}
{"continent":"Africa","country":"Kenya","total_flights":19920,"avg_ticket_price":778.45,"rank_in_continent":2}
{"continent":"Asia","country":"India","total_flights":39840,"avg_ticket_price":772.15,"rank_in_continent":1}
...
```

## ‚úÖ Krok 4: Weryfikacja wynik√≥w

### 4.1 Sprawd≈∫ pliki wyj≈õciowe

```bash
# Lista plik√≥w JSON
hadoop fs -ls /user/$(whoami)/projekt1/output6/

# Powinny byƒá:
# 000000_0  (lub podobne)
# _SUCCESS
```

### 4.2 Sprawd≈∫ format JSON

```bash
# Wy≈õwietl pierwsze 10 rekord√≥w
hadoop fs -cat /user/$(whoami)/projekt1/output6/* | head -10

# Ka≈ºda linia powinna byƒá poprawnym JSON-em:
# {"continent":"...","country":"...","total_flights":...,"avg_ticket_price":...,"rank_in_continent":...}
```

### 4.3 Weryfikuj poprawno≈õƒá danych

```bash
# Ile kontynent√≥w?
hadoop fs -cat /user/$(whoami)/projekt1/output6/* | \
  grep -o '"continent":"[^"]*"' | sort -u | wc -l
# Powinno byƒá 5-6 unikalnych kontynent√≥w

# Ile kraj√≥w?
hadoop fs -cat /user/$(whoami)/projekt1/output6/* | \
  grep -o '"country":"[^"]*"' | sort -u | wc -l
# Powinno byƒá znacznie mniej ni≈º 100 (bo nie wszystkie lotniska majƒÖ loty)

# Sprawd≈∫ ranking (rank_in_continent powinien byƒá 1, 2, 3... dla ka≈ºdego kontynentu)
hadoop fs -cat /user/$(whoami)/projekt1/output6/* | \
  jq -r '"\(.continent) \(.rank_in_continent) \(.country)"' | \
  sort | head -20
```

### 4.4 Pobierz wynik do lokalnego pliku

```bash
# Pobierz merged output
hadoop fs -getmerge /user/$(whoami)/projekt1/output6 output6_final.json

# Sprawd≈∫ lokalnie
cat output6_final.json | head -10

# Skopiuj na Windows
scp user@uczelnia:/tmp/projekt_hadoop/output6_final.json ~/Desktop/
```

## üß™ Test poprawno≈õci VIEW (opcjonalnie)

Je≈õli chcesz przetestowaƒá czy VIEW poprawnie parsuje wadliwe rekordy:

```bash
# Uruchom beeline
beeline -n "$(id -un)" -u jdbc:hive2://localhost:10000/default

# W beeline:
-- Sprawd≈∫ wadliwy rekord (7 p√≥l)
SELECT * FROM airports_table WHERE airport_id = 'CZRJ';
-- Powinno byƒá: airport_name = "Nitzsche, Heidenreich and Funk Airport"

-- Sprawd≈∫ poprawny rekord (6 p√≥l)
SELECT * FROM airports_table WHERE airport_id = 'AYWK';
-- Powinno byƒá: airport_name = "Ward Inc Airport"

-- Policz wszystkie rekordy (powinno byƒá 100)
SELECT COUNT(*) FROM airports_table;

-- Wyjd≈∫
!quit
```

## üêõ Troubleshooting

### Problem: "Permission denied" podczas uploadu do HDFS

```bash
# Sprawd≈∫ uprawnienia
hadoop fs -ls /user/$(whoami)/

# Utw√≥rz katalog je≈õli nie istnieje
hadoop fs -mkdir -p /user/$(whoami)/projekt1

# Ustaw uprawnienia
hadoop fs -chmod -R 755 /user/$(whoami)/projekt1
```

### Problem: MapReduce job failed

```bash
# Sprawd≈∫ logi YARN
yarn logs -applicationId <application_id>

# Sprawd≈∫ YARN UI
# http://<resource_manager_host>:8088
```

### Problem: Hive job failed - Tez/MR errors

```bash
# Je≈õli Tez nie dzia≈Ça, upewnij siƒô ≈ºe hive.hql u≈ºywa MR:
# Linia 5: SET hive.execution.engine=mr;

# Sprawd≈∫ logi Hive
beeline -n "$(id -un)" -u jdbc:hive2://localhost:10000/default -e "SHOW TABLES;"
```

### Problem: Puste wyniki w output6

```bash
# Sprawd≈∫ czy tabele sƒÖ utworzone
beeline -n "$(id -un)" -u jdbc:hive2://localhost:10000/default -e "SHOW TABLES;"

# Sprawd≈∫ czy dane sƒÖ w tabelach
beeline -n "$(id -un)" -u jdbc:hive2://localhost:10000/default -e "SELECT COUNT(*) FROM mapreduce_result;"
beeline -n "$(id -un)" -u jdbc:hive2://localhost:10000/default -e "SELECT COUNT(*) FROM airports_table;"

# Sprawd≈∫ czy JOIN dzia≈Ça
beeline -n "$(id -un)" -u jdbc:hive2://localhost:10000/default -e "
SET hive.execution.engine=mr;
SELECT COUNT(*)
FROM mapreduce_result mr
INNER JOIN airports_table a ON mr.departure_airport_id = a.airport_id;
"
```

## üìù Czyszczenie ≈õrodowiska

Po zako≈Ñczeniu test√≥w:

```bash
# Usu≈Ñ dane z HDFS
hadoop fs -rm -r /user/$(whoami)/projekt1

# Usu≈Ñ tabele Hive
beeline -n "$(id -un)" -u jdbc:hive2://localhost:10000/default -e "
DROP TABLE IF EXISTS mapreduce_result;
DROP TABLE IF EXISTS airports_raw;
DROP VIEW IF EXISTS airports_table;
DROP TABLE IF EXISTS output_json;
"

# Usu≈Ñ pliki lokalne
rm -rf /tmp/projekt_hadoop
```

## üìä Oczekiwane statystyki ko≈Ñcowe

Po pomy≈õlnym wykonaniu ca≈Çego pipeline:

| Krok | Input | Output | Oczekiwana liczba rekord√≥w |
|------|-------|--------|----------------------------|
| **MapReduce** | 1,000,100 lot√≥w | output_mr3 | ~300 grup (airport_id + status) |
| **Hive JOIN** | 300 grup + 100 lotnisk | po≈õrednie | ~300 po≈ÇƒÖczonych rekord√≥w |
| **Hive GROUP BY** | 300 rekord√≥w | po≈õrednie | ~50-70 kraj√≥w |
| **Hive RANK()** | 50-70 kraj√≥w | output6 (JSON) | ~50-70 rekord√≥w z rankingiem |

## ‚ú® Kluczowe features rozwiƒÖzania

1. **Combiner w MapReduce**: Redukcja ruchu sieciowego o ~97%
2. **Weighted Average**: Poprawna ≈õrednia wa≈ºona zamiast ≈õredniej ze ≈õrednich
3. **Intelligent CSV Parsing**: VIEW automatycznie naprawia b≈Çƒôdy w CSV (nazwy z przecinkami)
4. **Window Functions**: RANK() OVER dla rankingu kraj√≥w w kontynentach
5. **JSON Output**: Gotowe dane do dalszego przetwarzania w Airflow

## üìû Wsparcie

Je≈õli napotkasz problemy:
1. Sprawd≈∫ logi YARN: `yarn logs -applicationId <app_id>`
2. Sprawd≈∫ Web UI: http://<host>:8088
3. Sprawd≈∫ logi Hive: beeline + query z SET hive.execution.engine=mr

Powodzenia! üöÄ
